#!/usr/bin/env python3
import rclpy
from rclpy.node import Node
from tf2_ros import Buffer, TransformListener
from geometry_msgs.msg import PointStamped, PoseStamped
import pyrealsense2 as rs
import numpy as np
import cv2
from ultralytics import YOLO
import math
import time
import tf2_geometry_msgs


class TrashcanExplorer(Node):
    def __init__(self):
        super().__init__('trashcan_explorer_node')

        # ===== Publisher =====
        self.pub_candidates = self.create_publisher(PoseStamped, '/trashcan_candidates', 10)

        # ===== TFè¨­å®š =====
        self.tf_buffer = Buffer()
        self.tf_listener = TransformListener(self.tf_buffer, self)

        # ===== YOLOãƒ¢ãƒ‡ãƒ« =====
        self.model1 = YOLO(r"/home/araishogo/hotel_ws/src/best (8).pt")
        self.model2 = YOLO(r"/home/araishogo/hotel_ws/src/best2.pt")

        # ===== RealSenseåˆæœŸåŒ– =====
        self.pipeline = rs.pipeline()
        self.config = rs.config()
        self.config.enable_stream(rs.stream.color, 1280, 720, rs.format.bgr8, 30)
        self.config.enable_stream(rs.stream.depth, 1280, 720, rs.format.z16, 30)
        self.align = rs.align(rs.stream.color)

        self.get_logger().info("ğŸ“· RealSenseèµ·å‹•ä¸­...")
        self.pipeline.start(self.config)
        for _ in range(30):
            self.pipeline.wait_for_frames()

        self.capture_and_detect()

    # ===== TFå¾…æ©Ÿ =====
    def wait_for_tf(self, target='base_link', source='camera_camera_camera_link', timeout_sec=5.0):
        start = time.time()
        while rclpy.ok():
            if self.tf_buffer.can_transform(target, source, rclpy.time.Time()):
                return True
            if time.time() - start > timeout_sec:
                self.get_logger().warn("âš ï¸ TFå—ä¿¡ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
                return False
            rclpy.spin_once(self, timeout_sec=0.1)
            time.sleep(0.1)
        return False

    # ===== ã‚«ãƒ¡ãƒ©ãƒ­ãƒ¼ãƒ«è§’å–å¾— =====
    def get_camera_roll(self):
        try:
            trans = self.tf_buffer.lookup_transform('base_link', 'camera_camera_camera_link', rclpy.time.Time())
            q = trans.transform.rotation
            sinr_cosp = 2.0 * (q.w * q.x + q.y * q.z)
            cosr_cosp = 1.0 - 2.0 * (q.x**2 + q.y**2)
            roll = math.pi + math.atan2(sinr_cosp, cosr_cosp)
            self.get_logger().info(f"ğŸ“ ã‚«ãƒ¡ãƒ©ãƒ­ãƒ¼ãƒ«: {math.degrees(roll):.2f}Â°")
            return roll
        except Exception as e:
            self.get_logger().warn(f"âš ï¸ ãƒ­ãƒ¼ãƒ«è§’å–å¾—å¤±æ•—: {e}")
            return 0.0

    # ===== bboxä¸­å¿ƒã‚’BaseLinkã¸å¤‰æ› =====
    def project_to_baselink(self, cx, cy, depth, intrinsics):
        X = (cx - intrinsics.ppx) * depth / intrinsics.fx
        Y = (cy - intrinsics.ppy) * depth / intrinsics.fy
        Z = depth

        pt_cam = PointStamped()
        pt_cam.header.frame_id = 'camera_camera_camera_link'
        pt_cam.header.stamp = rclpy.time.Time().to_msg()
        pt_cam.point.x = X
        pt_cam.point.y = Y
        pt_cam.point.z = Z

        try:
            pt_base = self.tf_buffer.transform(pt_cam, 'base_link', timeout=rclpy.duration.Duration(seconds=1.0))
            return pt_base.point.x, pt_base.point.y, pt_base.point.z
        except Exception as e:
            self.get_logger().warn(f"âš ï¸ TFå¤‰æ›å¤±æ•—: {e}")
            return None

    # ===== ãƒ¡ã‚¤ãƒ³å‡¦ç† =====
    def capture_and_detect(self):
        try:
            frames = self.pipeline.wait_for_frames()
            aligned = self.align.process(frames)
            color_frame = aligned.get_color_frame()
            depth_frame = aligned.get_depth_frame()
            if not color_frame or not depth_frame:
                raise RuntimeError("âŒ ãƒ•ãƒ¬ãƒ¼ãƒ å–å¾—å¤±æ•—")

            color_img = np.asanyarray(color_frame.get_data())
            intr = depth_frame.profile.as_video_stream_profile().get_intrinsics()
            fx, fy = intr.fx, intr.fy

            self.get_logger().info("ğŸ§  YOLOç¬¬1æ®µæ¨è«–ä¸­...")
            res1 = self.model1.predict(source=color_img, conf=0.2, verbose=False)[0]
            canvas = color_img.copy()

            if not self.wait_for_tf():
                self.get_logger().warn("âš ï¸ TFæœªå–å¾—ã®ãŸã‚å¤‰æ›ã‚¹ã‚­ãƒƒãƒ—")

            roll = self.get_camera_roll()  # ã‚«ãƒ¡ãƒ©ãƒ­ãƒ¼ãƒ«è§’ï¼ˆãƒ©ã‚¸ã‚¢ãƒ³ï¼‰

            final_candidates = []  # ãƒ•ã‚£ãƒ«ã‚¿ã‚’é€šéã—ãŸå€™è£œãƒªã‚¹ãƒˆ

            for b in res1.boxes:
                x1, y1, x2, y2 = map(int, b.xyxy[0].tolist())
                crop = color_img[y1:y2, x1:x2]
                if crop.size == 0:
                    continue

                res2 = self.model2.predict(source=crop, conf=0.1, verbose=False)[0]
                if len(res2.boxes) == 0:
                    continue

                best_box = res2.boxes[0]
                xx1, yy1, xx2, yy2 = map(int, best_box.xyxy[0].tolist())
                gx1, gy1, gx2, gy2 = x1 + xx1, y1 + yy1, x1 + xx2, y1 + yy2
                cx, cy = int((gx1 + gx2) / 2), int((gy1 + gy2) / 2)
                depth = depth_frame.get_distance(cx, cy)
                if depth == 0:
                    continue

                # ==== å®Ÿå¯¸é«˜ã•è¨ˆç®— ====
                pixel_height = gy2 - gy1
                pixel_width = gx2 - gx1
                pixel_to_meter = depth / fy
                real_height = pixel_height * pixel_to_meter * abs(math.sin(roll))

                # ==== ãƒ•ã‚£ãƒ«ã‚¿æ¡ä»¶ ====
                height_ok = 0.25 <= real_height <= 0.4
                shape_ok = pixel_height > pixel_width

                if height_ok and shape_ok:
                    base_coords = self.project_to_baselink(cx, cy, depth, intr)
                    if base_coords:
                        bx, by, bz = base_coords
                        final_candidates.append((gx1, gy1, gx2, gy2, bx, by, bz, real_height))

                        # === ãƒˆãƒ”ãƒƒã‚¯å‡ºåŠ› ===
                        pose_msg = PoseStamped()
                        pose_msg.header.stamp = self.get_clock().now().to_msg()
                        pose_msg.header.frame_id = "base_link"
                        pose_msg.pose.position.x = bx
                        pose_msg.pose.position.y = by
                        pose_msg.pose.position.z = bz
                        pose_msg.pose.orientation.w = 1.0
                        self.pub_candidates.publish(pose_msg)
                        self.get_logger().info(f"ğŸ“¡ Publishå€™è£œ: ({bx:.2f}, {by:.2f}, {bz:.2f})")

            # ==== ãƒ•ã‚£ãƒ«ã‚¿çµæœã®å¯è¦–åŒ–ï¼ˆä¿æŒï¼‰ ====
            if len(final_candidates) == 0:
                self.get_logger().info("ğŸš« è©²å½“ã™ã‚‹å€™è£œãªã—")
            else:
                for gx1, gy1, gx2, gy2, bx, by, bz, real_height in final_candidates:
                    label = f"({bx:.2f}, {by:.2f})m  H={real_height:.2f}m"
                    cv2.putText(canvas, label, (gx1, gy1 - 8), cv2.FONT_HERSHEY_SIMPLEX, 0.55, (0, 255, 255), 2)
                    cv2.rectangle(canvas, (gx1, gy1), (gx2, gy2), (0, 255, 255), 2)
                    self.get_logger().info(
                        f"ğŸ¯ æœ€çµ‚å€™è£œ: x={bx:.3f}, y={by:.3f}, z={bz:.3f}, é«˜ã•={real_height:.3f}m"
                    )

                # ==== è¡¨ç¤ºã‚’ä¿æŒ ====
                scale = 640 / canvas.shape[1]
                resized = cv2.resize(canvas, None, fx=scale, fy=scale)
                cv2.imshow("YOLO Final Candidates (with Publish)", resized)
                cv2.waitKey(0)
                cv2.destroyAllWindows()

        finally:
            self.pipeline.stop()
            self.get_logger().info("ğŸ›‘ RealSenseã‚¹ãƒˆãƒªãƒ¼ãƒ åœæ­¢")


def main(args=None):
    rclpy.init(args=args)
    node = TrashcanExplorer()
    node.destroy_node()
    rclpy.shutdown()


if __name__ == '__main__':
    main()
